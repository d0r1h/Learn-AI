{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMMxhIGDD8BBzZvtUVRy5dz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["[Website Pytorch.io](https://www.learnpytorch.io/)"],"metadata":{"id":"sK6QjgpIDmty"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_8LefbqADSQM","executionInfo":{"status":"ok","timestamp":1767328391654,"user_tz":-330,"elapsed":3487,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"c1864361-bf70-4797-969e-77c21b1225d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.9.0+cpu\n","2.0.2\n"]}],"source":["import torch\n","import numpy as np\n","\n","print(torch.__version__)\n","print(np.__version__)"]},{"cell_type":"markdown","source":["__PyTorch Main Componetns__"],"metadata":{"id":"Id_7oql_VleM"}},{"cell_type":"markdown","source":["1. **Tensors** - N-dimensional arrays that serve as PyTorch’s fundamental data structure. They support automatic differentiation, hardware acceleration, and provide a comprehensive API for mathematical operations. Like NumPy arrays, but GPU-accelerated.\n","\n","2. **Autograd** - PyTorch’s automatic differentiation engine that tracks operations performed on tensors and builds a computational graph dynamically to be able to compute gradients.\n","\n","3. **Neural Network API** - A modular framework for building neural networks with pre-defined layers, activation functions, and loss functions. The `nn.Module` base class provides a clean interface for creating custom network architectures with parameter management.\n","\n","4. **DataLoaders** - Tools for efficient data handling that provide features like batching, shuffling, and parallel data loading. They abstract away the complexities of data preprocessing and iteration, allowing for optimized training loops."],"metadata":{"id":"ToSA0HskVpXI"}},{"cell_type":"markdown","source":["[__Tensors__](https://docs.pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html)\n","\n","\n","Tensors are the fundamental building block of machine learning.\n","\n","Their job is to represent data in a numerical way.\n","\n","For example, you could represent an image as a tensor with shape [3, 224, 224] which would mean [colour_channels, height, width], as in the image has 3 colour channels (red, green, blue), a height of 224 pixels and a width of 224 pixels."],"metadata":{"id":"aECLgTbCXyvl"}},{"cell_type":"markdown","source":["![image1](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-tensor-shape-example-of-image.png)"],"metadata":{"id":"wUK4RuCIYPl2"}},{"cell_type":"markdown","source":["The tensor would have three dimensions, one for colour_channels, height and\n","width."],"metadata":{"id":"gDz03VrWYbPD"}},{"cell_type":"code","source":["# A scalar is a single number and in tensor-speak it's a zero dimension tensor.\n","\n","scaler = torch.tensor(5)\n","\n","print(scaler)\n","print(scaler.dtype) # although scalar is a single number, it's of type torch.Tensor\n","print(scaler.shape) # a scalar has no shape\n","print(scaler.ndim) # scaler has 0 dimenstion\n","print(scaler.item()) # get the python number within a tensor (works only with one-dimensional) tensors"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T7Ze5fo6VoZQ","executionInfo":{"status":"ok","timestamp":1767328394675,"user_tz":-330,"elapsed":79,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"dbb19c66-8bbf-42f9-9aa3-6ec38110be9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(5)\n","torch.int64\n","torch.Size([])\n","0\n","5\n"]}]},{"cell_type":"code","source":["# A vector is a single dimension tensor but can contain many numbers.\n","\n","vector = torch.tensor([7,7])\n","\n","print(vector)\n","print(vector.dtype)\n","print(vector.shape)\n","print(vector.ndim)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0dQKJD5lZUso","executionInfo":{"status":"ok","timestamp":1767328396197,"user_tz":-330,"elapsed":9,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"c7176b9f-bbd6-4df7-90f0-213a61d4d3c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([7, 7])\n","torch.int64\n","torch.Size([2])\n","1\n"]}]},{"cell_type":"code","source":["# Matrix : Vector with extra dimensions\n","\n","\n","Matrix = torch.tensor([[1,2],[1,2]])\n","\n","\n","print(Matrix)\n","print(Matrix.dtype)\n","print(Matrix.shape)\n","print(Matrix.ndim)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TovvDadzZQCc","executionInfo":{"status":"ok","timestamp":1767328397279,"user_tz":-330,"elapsed":14,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"7908fc51-a5f8-4291-d0d1-4264273708c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 2],\n","        [1, 2]])\n","torch.int64\n","torch.Size([2, 2])\n","2\n"]}]},{"cell_type":"code","source":["tensor = torch.tensor([[1,2,3],\n","                      [4,5,6],\n","                      [7,8,9]])\n","\n","\n","print(tensor)\n","print(tensor.dtype)\n","print(tensor.shape)\n","print(tensor.ndim)\n","print('\\n')\n","\n","\n","# adding one more dimension in the same Tensor\n","tensor = torch.tensor([[[1,2,3],\n","                      [4,5,6],\n","                      [7,8,9]]])\n","\n","\n","print(tensor)\n","print(tensor.dtype)\n","print(tensor.shape)\n","print(tensor.ndim)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xok8rnz1bjq0","executionInfo":{"status":"ok","timestamp":1767328398572,"user_tz":-330,"elapsed":13,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"83ea822f-5d54-4dff-d3b4-94a25951d59f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 2, 3],\n","        [4, 5, 6],\n","        [7, 8, 9]])\n","torch.int64\n","torch.Size([3, 3])\n","2\n","\n","\n","tensor([[[1, 2, 3],\n","         [4, 5, 6],\n","         [7, 8, 9]]])\n","torch.int64\n","torch.Size([1, 3, 3])\n","3\n"]}]},{"cell_type":"markdown","source":["![](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-different-tensor-dimensions.png)"],"metadata":{"id":"v3HlQTfGdMLj"}},{"cell_type":"markdown","source":["### **Tensors Initialization**"],"metadata":{"id":"6nYl8RT4eFU_"}},{"cell_type":"markdown","source":["We've established tensors represent some form of data.\n","\n","And machine learning models such as neural networks manipulate and seek patterns within tensors.\n","\n","But when building machine learning models with PyTorch, it's rare you'll create tensors by hand (like what we've been doing).\n","\n","Instead, a machine learning model often starts out with large random tensors of numbers and adjusts these random numbers as it works through data to better represent it.\n","\n","In essence:\n","\n","`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers...`"],"metadata":{"id":"-sbf-LXeeU-G"}},{"cell_type":"markdown","source":["**Random**"],"metadata":{"id":"JfK3dw-_eTw5"}},{"cell_type":"code","source":["random_tensor = torch.rand(3,4) # Uniform distribution [0, 1)\n","\n","print(random_tensor.dtype)\n","print(random_tensor)\n","print('\\n')\n","\n","\n","\n","random_tensor = torch.randn(3,4) # Normal distribution (mean=0, std=1)\n","\n","print(random_tensor.dtype)\n","print(random_tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gP9Lc4WZcLsY","executionInfo":{"status":"ok","timestamp":1767328402254,"user_tz":-330,"elapsed":103,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"94c022dc-dda0-45ea-9b09-1cd7a7e05659"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.float32\n","tensor([[0.9686, 0.8343, 0.6405, 0.5475],\n","        [0.1293, 0.8296, 0.8670, 0.4522],\n","        [0.9253, 0.0679, 0.1862, 0.7701]])\n","\n","\n","torch.float32\n","tensor([[-0.7272, -0.0519,  0.5817,  0.0115],\n","        [ 1.2805,  0.9161, -0.9852,  0.2031],\n","        [ 0.4616,  0.3559,  0.0850,  0.8072]])\n"]}]},{"cell_type":"markdown","source":["**Zeros & Ones**"],"metadata":{"id":"H0PPMpqOggRb"}},{"cell_type":"code","source":["zeros = torch.zeros(2,2)\n","ones = torch.ones(2,2)\n","\n","print(zeros)\n","print(ones)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6_DfxHWqbgIT","executionInfo":{"status":"ok","timestamp":1767328403383,"user_tz":-330,"elapsed":31,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"3c5e16ae-6d00-4cc2-8f2a-71e1536272bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0., 0.],\n","        [0., 0.]])\n","tensor([[1., 1.],\n","        [1., 1.]])\n"]}]},{"cell_type":"code","source":["# Range\n","\n","range_tensor = torch.arange(start=0,end=10,step=2)\n","print(range_tensor)\n","\n","# likes : we use this when we want to create tensor with shape as another tensor\n","\n","zeros_like = torch.zeros_like(input=range_tensor)\n","ones_like = torch.ones_like(input=range_tensor)\n","\n","print(zeros_like)\n","print(ones_like)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fHhXhtAOgaiy","executionInfo":{"status":"ok","timestamp":1767328404837,"user_tz":-330,"elapsed":22,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"c9712905-e2cd-42df-a0e3-2ecb82754247"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0, 2, 4, 6, 8])\n","tensor([0, 0, 0, 0, 0])\n","tensor([1, 1, 1, 1, 1])\n"]}]},{"cell_type":"markdown","source":["**constant value**"],"metadata":{"id":"V3IkApGThtBi"}},{"cell_type":"code","source":["constant  = torch.full(size=(2,2),fill_value=5)\n","print(constant)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EDosBieNZOwM","executionInfo":{"status":"ok","timestamp":1767328406266,"user_tz":-330,"elapsed":17,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"9dff3b4d-06f5-4eeb-932f-589e2f89e2ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[5, 5],\n","        [5, 5]])\n"]}]},{"cell_type":"markdown","source":["**Tensor for neural network weights**"],"metadata":{"id":"4rd5xwo7h38n"}},{"cell_type":"code","source":["import torch.nn as nn\n","\n","'''\n","xavier_uniform_ : It's a weight initialization method designed to keep the variance of activations stable as they flow forward and backward through a network\n","\n","Best for : Tanh, Sigmoid, Linear (no activation)\n","Not ideal for: ReLU / LeakyReLU → use Kaiming (He) instead\n","\n","'''\n","\n","tensor = torch.empty(size = (128,256))\n","tensor1 = nn.init.xavier_uniform_(tensor)\n","print(tensor1, '\\n')\n","\n","tensor2 = nn.init.xavier_uniform_(tensor, gain=nn.init.calculate_gain(\"tanh\"))\n","print(tensor2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F6CylWj9ZJS0","executionInfo":{"status":"ok","timestamp":1767328407249,"user_tz":-330,"elapsed":23,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"1b05955a-74c5-4afb-b80e-9113e772ee3e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.0644,  0.0502, -0.0176,  ..., -0.0169, -0.0115, -0.0548],\n","        [ 0.0575, -0.1050,  0.1206,  ..., -0.0751,  0.0376,  0.0694],\n","        [ 0.0492,  0.0062,  0.0015,  ..., -0.0639,  0.0874, -0.1211],\n","        ...,\n","        [ 0.1195, -0.0909, -0.0271,  ..., -0.0724, -0.1009,  0.0855],\n","        [-0.0762,  0.0769,  0.1233,  ...,  0.1108,  0.0545,  0.0496],\n","        [-0.0509,  0.1181,  0.0071,  ..., -0.0215, -0.0201, -0.0846]]) \n","\n","tensor([[ 0.1640, -0.1141, -0.1349,  ..., -0.1657,  0.1073,  0.1758],\n","        [ 0.1129, -0.0097,  0.1992,  ...,  0.0474,  0.0726,  0.1032],\n","        [-0.0558,  0.0454, -0.0380,  ..., -0.0821, -0.1730,  0.1064],\n","        ...,\n","        [ 0.1176,  0.0189,  0.0362,  ..., -0.1163,  0.1451, -0.1208],\n","        [-0.0481,  0.1588,  0.1573,  ..., -0.1779, -0.1925, -0.0299],\n","        [ 0.1935,  0.0190, -0.0414,  ..., -0.0389, -0.0669,  0.0923]])\n"]}]},{"cell_type":"markdown","source":["### **Tensor Data Type**\n","\n","\n","\n","There are different type of datatypes in Pytorch and is to do with precision in computing. Precision is the amount of detail used to describe a number."],"metadata":{"id":"5DlXiOz9jOsp"}},{"cell_type":"code","source":["tensor_float_32 = torch.tensor([1,5,6],\n","                               dtype=torch.float32,\n","                               device=None)\n","\n","\n","tensor_float_16 = torch.tensor([1,5,6],\n","                               dtype=torch.float16,\n","                               device=None)\n","\n","print(tensor_float_32.dtype, tensor_float_32)\n","print(tensor_float_16.dtype, tensor_float_16)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ehFRWZE_ZHIQ","executionInfo":{"status":"ok","timestamp":1767328409059,"user_tz":-330,"elapsed":21,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"0afb927b-045b-4d75-cf54-3047aa3bbbec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.float32 tensor([1., 5., 6.])\n","torch.float16 tensor([1., 5., 6.], dtype=torch.float16)\n"]}]},{"cell_type":"markdown","source":["Aside from shape issues (tensor shapes don't match up), two of the other most common issues you'll come across in PyTorch are datatype and device issues.\n","\n","- one of tensors is torch.float32 and the other is torch.float16 (PyTorch often likes tensors to be the same format)\n","- one of your tensors is on the CPU and the other is on the GPU (PyTorch likes calculations between tensors to be on the same device)."],"metadata":{"id":"unHu_kJGk5r3"}},{"cell_type":"markdown","source":["### **Tensors Operations**"],"metadata":{"id":"1EeRsmL-lN0a"}},{"cell_type":"code","source":["# vector opetation\n","\n","tensor = torch.tensor([1,2,3])\n","\n","print(tensor + 10, torch.add(tensor,10))\n","print(tensor * 10, torch.mul(tensor,10))\n","print(tensor - 10, torch.sub(tensor,10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EIuaHdqhVKaZ","executionInfo":{"status":"ok","timestamp":1767328609910,"user_tz":-330,"elapsed":19,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"59813374-0aa6-4846-8906-e9e3c8b9557e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([11, 12, 13]) tensor([11, 12, 13])\n","tensor([10, 20, 30]) tensor([10, 20, 30])\n","tensor([-9, -8, -7]) tensor([-9, -8, -7])\n"]}]},{"cell_type":"markdown","source":["Matrix Operations : PyTorch implements matrix multiplication functionality in the [torch.matmul()](https://docs.pytorch.org/docs/stable/generated/torch.matmul.html) method\n"],"metadata":{"id":"dvFn_dpSAnQa"}},{"cell_type":"code","source":["'''\n","The inner dimensions must match:\n","\n","    (3, 2) @ (3, 2) won't work\n","    (2, 3) @ (3, 2) will work\n","    (3, 2) @ (2, 3) will work\n","\n","\n","The resulting matrix has the shape of the outer dimensions:\n","\n","    (2, 3) @ (3, 2) -> (2, 2)\n","    (3, 2) @ (2, 3) -> (3, 3)\n","\n","\"@\" in Python is the symbol for matrix multiplication.\n","'''\n","\n","tensor = torch.tensor([1,2,3])\n","\n","# Element wise multiplication\n","print(tensor * tensor)\n","print(torch.mul(tensor,tensor))\n","\n","\n","# Dot product (inner product) [A matrix multiplication also referred to as the dot product of two matrices]\n","print(tensor @ tensor)\n","print(torch.matmul(tensor,tensor))\n","\n","\n","# Same we can do in python\n","print(sum([(i*i) for i in tensor]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"niJQoGtrDmZz","executionInfo":{"status":"ok","timestamp":1767329948854,"user_tz":-330,"elapsed":12,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"27229649-af52-4ee7-dae7-23cee0639409"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 4, 9])\n","tensor([1, 4, 9])\n","tensor(14)\n","tensor(14)\n","tensor(14)\n"]}]},{"cell_type":"markdown","source":["Neural networks are full of matrix multiplications and dot products. The `torch.nn.Linear()` module, also known as a feed-forward layer or fully connected layer, implements a matrix multiplication between an input x and a weights matrix A."],"metadata":{"id":"jbjwAL4TJmjA"}},{"cell_type":"code","source":["torch.manual_seed(42)\n","\n","linear = nn.Linear(in_features=2,\n","                   out_features=6)\n","\n","tensor = torch.tensor([[1, 2],\n","                         [3, 4],\n","                         [5, 6]], dtype=torch.float32)\n","\n","output = linear(tensor)\n","\n","\n","print(tensor.shape)\n","print(output.shape, '\\n')\n","\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v1L6crrRBqzC","executionInfo":{"status":"ok","timestamp":1767331492567,"user_tz":-330,"elapsed":16,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"fdff5196-e352-4b22-9dda-3945b9830857"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 2])\n","torch.Size([3, 6]) \n","\n","tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n","        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n","        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n","       grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"code","source":["# Finding index of the max and min value in the tensor\n","\n","tensor = torch.tensor([1,6,2,5,0])\n","\n","print(torch.argmax(tensor), torch.max(tensor))\n","print(torch.argmin(tensor), torch.min(tensor))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ro_2ywKNDmXq","executionInfo":{"status":"ok","timestamp":1767331857744,"user_tz":-330,"elapsed":11,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"b36554eb-19a3-4f26-9e11-86d02ab7d247"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1) tensor(6)\n","tensor(4) tensor(0)\n"]}]},{"cell_type":"code","source":["# Testing with different tensor data type\n","\n","tensor1 = torch.tensor([1,2,3],dtype=torch.float32)\n","tensor2 = torch.tensor([1,2,3],dtype=torch.float16)\n","\n","print(tensor1)\n","print('\\n')\n","print(tensor2)\n","\n","print(tensor1  @ tensor2) # check the following error we got (so we need to have the same data type), Let's keep this error"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":257},"id":"RfeykayYDmVd","executionInfo":{"status":"error","timestamp":1767332383491,"user_tz":-330,"elapsed":82,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"1f3b3b94-6805-4d15-c7d1-65fac1cfe673"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 2., 3.])\n","\n","\n","tensor([1., 2., 3.], dtype=torch.float16)\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"dot : expected both vectors to have same dtype, but found Float and Half","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2588114695.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m  \u001b[0;34m@\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: dot : expected both vectors to have same dtype, but found Float and Half"]}]},{"cell_type":"markdown","source":["### **Dimension manipulation of your tensors**"],"metadata":{"id":"vRQvbZWROeIw"}},{"cell_type":"markdown","source":["__Reshaping, stacking, squeezing and unsqueezing__\n","\n","\n","1. `torch.reshape(input, shape)`\tReshapes input to shape (if compatible), can also use torch.Tensor.reshape().\n","2. `Tensor.view(shape)`\tReturns a view of the original tensor in a different shape but shares the same data as the original tensor.\n","3. `torch.stack(tensors, dim=0)`\tConcatenates a sequence of tensors along a new dimension (dim), all tensors must be same size.\n","4. `torch.squeeze(input)`\tSqueezes input to remove all the dimenions with value 1.\n","5. `torch.unsqueeze(input, dim)`\tReturns input with a dimension value of 1 added at dim.\n","6. `torch.permute(input, dims)`\tReturns a view of the original input with its dimensions permuted (rearranged) to dims."],"metadata":{"id":"I-s1fdn6QYGk"}},{"cell_type":"code","source":["tensor = torch.arange(1,12,2)\n","\n","tensor, tensor.ndim, tensor.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6MaRgmhaDmQ9","executionInfo":{"status":"ok","timestamp":1767333371178,"user_tz":-330,"elapsed":50,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"43398972-b228-404b-a126-bee8a2568ac6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([ 1,  3,  5,  7,  9, 11]), 1, torch.Size([6]))"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["reshape_tensor_1 = tensor.reshape(1, 6) # added one extra dimension  (row, column)\n","reshape_tensor_2 = tensor.reshape(3, 2)\n","\n","\n","print(reshape_tensor_1, reshape_tensor_1.ndim, reshape_tensor_1.shape)\n","print(reshape_tensor_2, reshape_tensor_2.ndim, reshape_tensor_2.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xy9jRAUTDmLA","executionInfo":{"status":"ok","timestamp":1767333434011,"user_tz":-330,"elapsed":10,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"e9b902d9-a494-44ab-dc22-7e0d0ce94c94"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1,  3,  5,  7,  9, 11]]) 2 torch.Size([1, 6])\n","tensor([[ 1,  3],\n","        [ 5,  7],\n","        [ 9, 11]]) 2 torch.Size([3, 2])\n"]}]},{"cell_type":"code","source":["# Sctaking\n","\n","print(tensor, '\\n')\n","print(torch.stack([tensor,tensor],dim=0), '\\n')\n","print(torch.stack([tensor,tensor],dim=1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kFUpe4toDmIu","executionInfo":{"status":"ok","timestamp":1767333690373,"user_tz":-330,"elapsed":15,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"7f8b9b35-0901-471e-8eff-2f51aaf97633"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 1,  3,  5,  7,  9, 11]) \n","\n","tensor([[ 1,  3,  5,  7,  9, 11],\n","        [ 1,  3,  5,  7,  9, 11]]) \n","\n","tensor([[ 1,  1],\n","        [ 3,  3],\n","        [ 5,  5],\n","        [ 7,  7],\n","        [ 9,  9],\n","        [11, 11]])\n"]}]},{"cell_type":"code","source":["# squeeze\n","\n","print(reshape_tensor_1, reshape_tensor_1.ndim, reshape_tensor_1.shape)\n","squeeze_tensor = torch.squeeze(reshape_tensor_1)\n","print('\\n')\n","print(squeeze_tensor, squeeze_tensor.ndim, squeeze_tensor.shape)\n","print('\\n')\n","un_squeeze_tensor = torch.unsqueeze(squeeze_tensor, dim=1)\n","print(un_squeeze_tensor, un_squeeze_tensor.ndim, un_squeeze_tensor.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FVSJUl0GRoh1","executionInfo":{"status":"ok","timestamp":1767334857663,"user_tz":-330,"elapsed":18,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"002a5dc3-8aa1-4ca6-d68c-276b78963520"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1,  3,  5,  7,  9, 11]]) 2 torch.Size([1, 6])\n","\n","\n","tensor([ 1,  3,  5,  7,  9, 11]) 1 torch.Size([6])\n","\n","\n","tensor([[ 1],\n","        [ 3],\n","        [ 5],\n","        [ 7],\n","        [ 9],\n","        [11]]) 2 torch.Size([6, 1])\n"]}]},{"cell_type":"code","source":["# Rearrange the order of axes values\n","\n","tensor = torch.rand(size=(5,5,3))\n","\n","print(tensor.size(), tensor.ndim)\n","\n","permute_tenosr = tensor.permute(2,0,1) # # shifts axis 0->1, 1->2, 2->0\n","\n","print(permute_tenosr.size(), permute_tenosr.ndim)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9760j_ULDmGn","executionInfo":{"status":"ok","timestamp":1767335172695,"user_tz":-330,"elapsed":13,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"d26deced-0609-4f3b-bc55-4c6536baad58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([5, 5, 3]) 3\n","torch.Size([3, 5, 5]) 3\n"]}]},{"cell_type":"markdown","source":["**Pssing NumPy aaray into PyTorch**"],"metadata":{"id":"vA4yCIxeZCnf"}},{"cell_type":"code","source":["array = np.arange(0,10)\n","print(array, array.dtype)\n","\n","array_tensor = torch.from_numpy(array)\n","print(array_tensor, array_tensor.dtype)\n","\n","array_tensor = torch.from_numpy(array).type(torch.float32)\n","print(array_tensor, array_tensor.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m4mfJ3tZDmEj","executionInfo":{"status":"ok","timestamp":1767335439531,"user_tz":-330,"elapsed":12,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"4c0ba00e-e189-4717-d74a-952ad1a34dd7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 2 3 4 5 6 7 8 9] int64\n","tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) torch.int64\n","tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]) torch.float32\n"]}]},{"cell_type":"code","source":["tensor = torch.ones(7)\n","print(tensor, tensor.numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R7560quqDl8D","executionInfo":{"status":"ok","timestamp":1767335799167,"user_tz":-330,"elapsed":13,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"ce0f43e8-c1af-4e5e-8733-371e9513e361"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 1., 1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1. 1. 1.]\n"]}]},{"cell_type":"markdown","source":["------"],"metadata":{"id":"wVGWRdNPbHXi"}},{"cell_type":"code","source":["# Create a random tensor with shape (7, 7)\n","\n","tensor = torch.rand(7,7)\n","print(tensor.size())\n","\n","\n","# Perform a matrix multiplication on the above tensor with another random tensor with shape (1, 7)\n","\n","tensor1 = torch.rand(1,7)\n","print(tensor1.shape)\n","\n","print(tensor.matmul(tensor1.T))\n","print('\\n')\n","\n","# Set the random seed to 0 and do above again.\n","\n","torch.manual_seed(0)\n","\n","tensor2 = torch.rand(7,7)\n","tensor3 = torch.rand(1,7)\n","\n","print(tensor2.matmul(tensor3.T))\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lCp1iyEeDl5y","executionInfo":{"status":"ok","timestamp":1767336604061,"user_tz":-330,"elapsed":13,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"57826d1d-b5a1-4c07-92c1-ae22f54e4acb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([7, 7])\n","torch.Size([1, 7])\n","tensor([[1.2239],\n","        [2.0847],\n","        [1.9002],\n","        [0.9408],\n","        [1.5213],\n","        [1.3606],\n","        [0.8780]])\n","\n","\n","tensor([[1.8542],\n","        [1.9611],\n","        [2.2884],\n","        [3.0481],\n","        [1.7067],\n","        [2.5290],\n","        [1.7989]])\n"]}]},{"cell_type":"code","source":["tensor = torch.rand(size=(1,1,1,10))\n","print(tensor)\n","print(tensor.ndim)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-PbCrnhkDl3h","executionInfo":{"status":"ok","timestamp":1767336709395,"user_tz":-330,"elapsed":52,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"0fa4b81e-edcd-4bd6-a632-3b29b218388a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[[0.5995, 0.0652, 0.5460, 0.1872, 0.0340, 0.9442, 0.8802, 0.0012,\n","           0.5936, 0.4158]]]])\n","4\n"]}]},{"cell_type":"code","source":["torch.manual_seed(7)\n","tensor_ones = torch.rand(10)\n","tensor_ones"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4utpXWCGDl1Z","executionInfo":{"status":"ok","timestamp":1767336842767,"user_tz":-330,"elapsed":14,"user":{"displayName":"PAWAN TRIVEDI","userId":"10146163769871521176"}},"outputId":"8dd9844a-6e23-4c9c-ad86-4bb3e030006e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n","        0.8513])"]},"metadata":{},"execution_count":109}]},{"cell_type":"markdown","source":["-----"],"metadata":{"id":"ab0NhKTYfHhM"}},{"cell_type":"markdown","source":["\n","1.   [PyTorch internals](https://blog.ezyang.com/2019/05/pytorch-internals/)\n","2.   [Working Class Deep Learner](https://marksaroufim.substack.com/p/working-class-deep-learner)\n","3. [Strides in PyTorch](https://chitrarth.substack.com/p/understanding-strides-in-pytorch)\n"],"metadata":{"id":"BAFy51yofMTb"}},{"cell_type":"markdown","source":["__Notes from the above blogs :)__"],"metadata":{"id":"IH3yTsLVfarw"}},{"cell_type":"markdown","source":["**Tensor** & **Stride**\n","\n","The tensor is the central data structure in PyTorch. You probably have a pretty good idea about what a tensor intuitively represents: its an n-dimensional data structure containing some sort of scalar type, e.g., floats, ints, et cetera. We can think of a tensor as consisting of some data, and then some metadata describing the size of the tensor, the type of the elements in contains (dtype), what device the tensor lives on (CPU memory? CUDA memory?)\n","\n","\n"],"metadata":{"id":"oFpskw16gAYA"}}]}