{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e6a2769-2d5d-49f2-8562-2d3ac792f400",
   "metadata": {},
   "source": [
    "### __Inside a Single RNN Layer (Vanilla RNN)__\n",
    "\n",
    "A single RNN layer maintains temporal memory by combining the current input and the previous hidden state using three shared weight matrices, producing both a new hidden state and an output at every time step.\n",
    "\n",
    "RNNs machinery is a bit more complex. Inside a single Recurrent Neural Network layer we have `3 weight matrices` as well as `2 input tensors` and `2 output tensors`.\n",
    "\n",
    "\n",
    "\n",
    "At each time step t, a basic RNN cell computes ht(hidden state output): \n",
    "\n",
    "$$\n",
    "h_t = \\phi\\left(W_{xh} x_t + W_{hh} h_{t-1} + b_h\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "y_t = W_{hy} h_t + b_y\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a745dff-df87-40d8-9ec9-c93660a5b9ff",
   "metadata": {},
   "source": [
    "![](https://i.sstatic.net/xFs0V.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eb9bb3-de5a-4904-a651-b08f4228b62a",
   "metadata": {},
   "source": [
    "- ϕ is a non-linear activation function such as tanh or ReLU\n",
    "- xt is the input at time step t\n",
    "- ht−1 is the previous hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16e4118-0312-43c3-b9ff-cf0180ec70b3",
   "metadata": {},
   "source": [
    "__Weight Matrices (3 Total)__\n",
    "\n",
    "\n",
    "1. Input → Hidden\n",
    "   \n",
    "$$\n",
    "W_{xh} \\in \\mathbb{R}^{d_{\\text{hidden}} \\times d_{\\text{input}}}\n",
    "$$\n",
    "\n",
    "2. Hidden → Hidden (Recurrent Weight)\n",
    "\n",
    "$$\n",
    "W_{hh} \\in \\mathbb{R}^{d_{\\text{hidden}} \\times d_{\\text{hidden}}}\n",
    "$$\n",
    "\n",
    "\n",
    "3. Hidden → Output\n",
    "\n",
    "$$\n",
    "W_{hy} \\in \\mathbb{R}^{d_{\\text{output}} \\times d_{\\text{hidden}}}\n",
    "$$\n",
    "\n",
    "These weight matrices are shared across all time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c776bf99-c15c-44ce-9284-2d7def554a4a",
   "metadata": {},
   "source": [
    "__Input Tensors (2)__\n",
    "\n",
    "At time step t:\n",
    "\n",
    "1. Current input\n",
    "2. Previous hidden state\n",
    "\n",
    "\n",
    "__Output Tensors (2)__\n",
    "\n",
    "1. Current hidden state\n",
    "2. Current output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea10a4-5750-48ac-8727-e5fc0222f158",
   "metadata": {},
   "source": [
    "![](https://contenthub-static.grammarly.com/blog/wp-content/uploads/2024/09/158474-6180-Blog-Visuals_-RNNs_V1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabde7aa-ffaa-4d77-858d-d9f3f39ed0d4",
   "metadata": {},
   "source": [
    "Recurrent Nets introduce a new concept called “hidden state”, which is simply another input based on previous layer outputs. But wait, if this is based on previous layer outputs, how do I get it for the first run? Simple, just start it with zeros.\n",
    "\n",
    "RNNs are fed in a different way than feedforward networks. Because we are working with sequences, the order that we input the data matters, this is why each time we feed the net, we have to input a single item in the sequence. for example if it’s a stock price, we input the stock price for each day. If it’s a text we enter a single letter/word each time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f1c786-9fcb-4297-896b-9b5f88faeae1",
   "metadata": {},
   "source": [
    "__Character RNN__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcf896fc-1b26-43b9-9924-abf5ae69e070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f389a6e9-530e-48da-812f-ec9b72b35a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\n",
    "    'mps' if torch.mps.is_available()\n",
    "    else 'cuda' if torch.cuda.is_available()\n",
    "    else 'cpu'\n",
    ")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9306cb3-ce68-4923-963e-ba86117d5c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ', 'I', 'P', 'a', 'm', 'n', 'w'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set('I am Pawan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab2c8ee6-06cd-42db-bf78-9b7d0978e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "\n",
    "    def _init__(self, text_data: str, seq_length:int = 25) -> None:\n",
    "\n",
    "        self.chars = sorted(list(set(text_data)))\n",
    "        self.data_size, self.vocab_size = len(text_data), len(self.chars)\n",
    "            \n",
    "        self.inx_to_char = {i:ch for i, ch in enumerate(self.chars)}\n",
    "        self.char_to_idx = {ch:i for i, ch in enumerate(self.chars)}\n",
    "        self.seq_length = seq_length\n",
    "        self.X = self.string_to_vector(text_data)\n",
    "\n",
    "    @property\n",
    "    def X_string(self) -> str:\n",
    "        return self.vector_to_string(self.X)\n",
    "\n",
    "    def _len__(self) -> int: \n",
    "        return int(len(self.X)/self.seq_length -1)\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[torch.tensor, torch.tensor]:\n",
    "        start_idx = index * self.seq_length\n",
    "        end_idx = (index + 1) * self.seq_length\n",
    "\n",
    "        X = torch.tensor(self.X[start_idx:end_idx]).float()\n",
    "        y = torch.tensor(self.y[start_idx+1:end_idx+1]).float()\n",
    "        return X, y\n",
    "\n",
    "    def string_to_vector(self, name:str) -> list[int]:\n",
    "        vector = list()\n",
    "        for s in name:\n",
    "            vector.append(self.char_to_idx[s])\n",
    "        return vector\n",
    "\n",
    "    def vector_to_string(self, vector: list[int]) -> str:\n",
    "        vector_string =  ''\n",
    "        for i in vector:\n",
    "            vector_string += self.inx_to_char[i]\n",
    "        return vector_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3465c6ab-15f0-47ab-87b0-cdbdd6dc97ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN Class \n",
    "\n",
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_size: int,\n",
    "                 hidden_size: int,\n",
    "                 output_size: int) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.batch_size  = batch_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size, hidden_size, bias=False) \n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, X, hidden_state) -> tuple[torch.tensor, torch.tensor]:\n",
    "\n",
    "        X = self.i2h(X)\n",
    "        hidden_state = self.h2h(hidden_state)\n",
    "        hidden_state = torch.tanh(X + hidden_state)\n",
    "        return self.h2o(hidden_state), hidden_state\n",
    "\n",
    "    def init_zero_hidden(self, batch_size=1) -> torch.tensor:\n",
    "        return torch.zeros(batch_size, self.hidden_size, requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ad42df-4be3-4175-9e24-67659321aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model: RNN, dataset: TextDataset, prediction_lengeth:int = 100) -> str:\n",
    "\n",
    "    model.eval()\n",
    "    predicted = dataset.vector_to_string([random.randint(0, len(dataset.chars) -1)])\n",
    "    hidden = model.init_zero_hidden()\n",
    "\n",
    "    for i in range(prediction_lengeth -1):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e50a76-6dc8-4583-93fc-7d6ffc513017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee0af1a-9e96-4319-a587-e8aa385162e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6c4b0c-79ef-43cf-868e-784b897a901c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62715964-e657-4ce2-98c6-a0c3da8d832b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60415de4-b71f-4b0e-9686-df58d09ee253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d75783-a032-4e9d-bd5c-5e8e0ea89bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563919ee-c0d3-4bbb-92f2-70ed2d886018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
